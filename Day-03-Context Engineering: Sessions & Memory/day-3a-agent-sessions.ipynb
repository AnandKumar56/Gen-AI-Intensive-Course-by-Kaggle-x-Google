{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Memory Management - Part 1 - Sessions\n",
    "\n",
    "**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n",
    "\n",
    "In this notebook, you'll learn:\n",
    "\n",
    "- ‚úÖ What sessions are and how to use them in your agent\n",
    "- ‚úÖ How to build *stateful* agents with sessions and events\n",
    "- ‚úÖ How to persist sessions in a database\n",
    "- ‚úÖ Context management practices such as context compaction\n",
    "- ‚úÖ Best practices for sharing session State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ÄºÔ∏è Please Read\n",
    "\n",
    "\n",
    "> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n",
    "> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n",
    "\n",
    "> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n",
    "\n",
    "> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n",
    "\n",
    "**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìñ Get started with Kaggle Notebooks\n",
    "\n",
    "If this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n",
    "\n",
    "Here's how to get started:\n",
    "\n",
    "**1. Verify Your Account (Required)**\n",
    "\n",
    "To use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n",
    "\n",
    "You can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n",
    "\n",
    "**2. Make Your Own Copy**\n",
    "\n",
    "To run any code in this notebook, you first need your own editable copy.\n",
    "\n",
    "Click the `Copy and Edit` button in the top-right corner.\n",
    "\n",
    "![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n",
    "\n",
    "This creates a private copy of the notebook just for you.\n",
    "\n",
    "**3. Run Code Cells**\n",
    "\n",
    "Once you have your copy, you can run code.\n",
    "\n",
    "Click the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n",
    "\n",
    "![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n",
    "\n",
    "Run the cells in order from top to bottom.\n",
    "\n",
    "**4. If You Get Stuck**\n",
    "\n",
    "To restart: Select `Factory reset` from the `Run` menu.\n",
    "\n",
    "For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è Section 1: Setup\n",
    "\n",
    "### 1.1: Install dependencies\n",
    "\n",
    "The Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n",
    "\n",
    "To install and use ADK in your own Python development environment outside of this course, you can do so by running:\n",
    "\n",
    "```\n",
    "pip install google-adk\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: Configure your Gemini API Key\n",
    "\n",
    "This notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n",
    "\n",
    "**1. Get your API key**\n",
    "\n",
    "If you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n",
    "\n",
    "**2. Add the key to Kaggle Secrets**\n",
    "\n",
    "Next, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n",
    "\n",
    "1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n",
    "2. Create a new secret with the label `GOOGLE_API_KEY`.\n",
    "3. Paste your API key into the \"Value\" field and click \"Save\".\n",
    "4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n",
    "\n",
    "**3. Authenticate in the notebook**\n",
    "\n",
    "Run the cell below to complete authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:41:12.906325Z",
     "iopub.status.busy": "2025-11-29T07:41:12.906052Z",
     "iopub.status.idle": "2025-11-29T07:41:20.433868Z",
     "shell.execute_reply": "2025-11-29T07:41:20.432897Z",
     "shell.execute_reply.started": "2025-11-29T07:41:12.906292Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-adk in /usr/local/lib/python3.11/dist-packages (1.18.0)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.3)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.11.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.6.5)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from google-adk) (8.3.0)\n",
      "Requirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.116.1)\n",
      "Requirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.177.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.125.0)\n",
      "Requirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\n",
      "Requirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.13.12)\n",
      "Requirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.25.0)\n",
      "Requirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.56.0)\n",
      "Requirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\n",
      "Requirement already satisfied: google-cloud-storage<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.5.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.48.0)\n",
      "Requirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21)\n",
      "Requirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.20.0)\n",
      "Requirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\n",
      "Requirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\n",
      "Requirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\n",
      "Requirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.12.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.32.5)\n",
      "Requirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.17.1)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.0.41)\n",
      "Requirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.47.2)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.15.0)\n",
      "Requirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from google-adk) (5.3.1)\n",
      "Requirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.35.0)\n",
      "Requirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.0)\n",
      "Requirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (46.0.3)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (6.33.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.35.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\n",
      "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\n",
      "Requirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\n",
      "Requirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (2.4.3)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-secret-manager<3.0.0,>=2.22.0->google-adk) (1.74.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\n",
      "Requirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<4.0.0,>=3.0.0->google-adk) (2.7.2)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\n",
      "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.11.0)\n",
      "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\n",
      "Requirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.3)\n",
      "Requirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\n",
      "Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.26.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.4)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.4.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, cachetools\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 6.33.0\n",
      "    Uninstalling protobuf-6.33.0:\n",
      "      Successfully uninstalled protobuf-6.33.0\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 6.2.1\n",
      "    Uninstalling cachetools-6.2.1:\n",
      "      Successfully uninstalled cachetools-6.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\n",
      "google-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\n",
      "ray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\n",
      "pydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\n",
      "pydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\n",
      "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cachetools-5.5.2 protobuf-5.29.5\n"
     ]
    }
   ],
   "source": [
    "!pip install google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:41:40.361213Z",
     "iopub.status.busy": "2025-11-29T07:41:40.360859Z",
     "iopub.status.idle": "2025-11-29T07:41:40.468423Z",
     "shell.execute_reply": "2025-11-29T07:41:40.467459Z",
     "shell.execute_reply.started": "2025-11-29T07:41:40.361176Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: Import ADK components\n",
    "\n",
    "Now, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:41:44.812254Z",
     "iopub.status.busy": "2025-11-29T07:41:44.811903Z",
     "iopub.status.idle": "2025-11-29T07:42:24.989585Z",
     "shell.execute_reply": "2025-11-29T07:42:24.988696Z",
     "shell.execute_reply.started": "2025-11-29T07:41:44.812231Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict\n",
    "\n",
    "from google.adk.agents import Agent, LlmAgent\n",
    "from google.adk.apps.app import App, EventsCompactionConfig\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.sessions import DatabaseSessionService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: Helper functions\n",
    "\n",
    "Helper function that manages a complete conversation session, handling session\n",
    "creation/retrieval, query processing, and response streaming. It supports\n",
    "both single queries and multiple queries in sequence.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    ">>> await run_session(runner, \"What is the capital of France?\", \"geography-session\")\n",
    ">>> await run_session(runner, [\"Hello!\", \"What's my name?\"], \"user-intro-session\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:42:35.031170Z",
     "iopub.status.busy": "2025-11-29T07:42:35.029724Z",
     "iopub.status.idle": "2025-11-29T07:42:35.039764Z",
     "shell.execute_reply": "2025-11-29T07:42:35.039055Z",
     "shell.execute_reply.started": "2025-11-29T07:42:35.031137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Define helper functions that will be reused throughout the notebook\n",
    "async def run_session(\n",
    "    runner_instance: Runner,\n",
    "    user_queries: list[str] | str = None,\n",
    "    session_name: str = \"default\",\n",
    "):\n",
    "    print(f\"\\n ### Session: {session_name}\")\n",
    "\n",
    "    # Get app name from the Runner\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    # Attempt to create a new session or retrieve an existing one\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=USER_ID, session_id=session_name\n",
    "        )\n",
    "\n",
    "    # Process queries if provided\n",
    "    if user_queries:\n",
    "        # Convert single query to list for uniform processing\n",
    "        if type(user_queries) == str:\n",
    "            user_queries = [user_queries]\n",
    "\n",
    "        # Process each query in the list sequentially\n",
    "        for query in user_queries:\n",
    "            print(f\"\\nUser > {query}\")\n",
    "\n",
    "            # Convert the query string to the ADK Content format\n",
    "            query = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "            # Stream the agent's response asynchronously\n",
    "            async for event in runner_instance.run_async(\n",
    "                user_id=USER_ID, session_id=session.id, new_message=query\n",
    "            ):\n",
    "                # Check if the event contains valid content\n",
    "                if event.content and event.content.parts:\n",
    "                    # Filter out empty or \"None\" responses before printing\n",
    "                    if (\n",
    "                        event.content.parts[0].text != \"None\"\n",
    "                        and event.content.parts[0].text\n",
    "                    ):\n",
    "                        print(f\"{MODEL_NAME} > \", event.content.parts[0].text)\n",
    "    else:\n",
    "        print(\"No queries!\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: Configure Retry Options\n",
    "\n",
    "When working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:43:06.445001Z",
     "iopub.status.busy": "2025-11-29T07:43:06.444362Z",
     "iopub.status.idle": "2025-11-29T07:43:06.449102Z",
     "shell.execute_reply": "2025-11-29T07:43:06.448294Z",
     "shell.execute_reply.started": "2025-11-29T07:43:06.444972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§π Section 2: Session Management\n",
    "\n",
    "### 2.1 The Problem\n",
    "\n",
    "At their core, Large Language Models are **inherently stateless**. Their awareness is confined to the information you provide in a single API call. This means an agent without proper context management will react to the current prompt without considering any previous history.\n",
    "\n",
    "**‚ùì Why does this matter?** Imagine trying to have a meaningful conversation with someone who forgets everything you've said after each sentence. That's the challenge we face with raw LLMs!\n",
    "\n",
    "In ADK, we use `Sessions` for **short term memory management** and `Memory` for **long term memory.** In the next notebook, you'll focus on `Memory`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 What is a Session?\n",
    "\n",
    "#### **üì¶ Session**\n",
    "\n",
    "A session is a container for conversations. It encapsulates the conversation history in a chronological manner and also records all tool interactions and responses for a **single, continuous conversation**. A session is tied to a user and agent; it is not shared with other users. Similarly, a session history for an Agent is not shared with other Agents.\n",
    "\n",
    "In ADK, a **Session** is comprised of two key components `Events` and `State`:\n",
    "\n",
    "**üìù Session.Events**:\n",
    "\n",
    "> While a session is a container for conversations, `Events` are the building blocks of a conversation.\n",
    ">\n",
    "> Example of Events:\n",
    "> - *User Input*: A message from the user (text, audio, image, etc.)\n",
    "> - *Agent Response*: The agent's reply to the user\n",
    "> - *Tool Call*: The agent's decision to use an external tool or API\n",
    "> - *Tool Output*: The data returned from a tool call, which the agent uses to continue its reasoning\n",
    "    \n",
    "\n",
    "**{} Session.State**:\n",
    "\n",
    "> `session.state` is the Agent's scratchpad, where it stores and updates dynamic details needed during the conversation. Think of it as a global `{key, value}` pair storage which is available to all subagents and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/session-state-and-events.png\" width=\"320\" alt=\"Session state and events\">\n",
    "\n",
    "<!-- ```mermaid\n",
    "graph TD\n",
    "    subgraph A[\"Agentic Application\"];\n",
    "        subgraph U[\"User\"]\n",
    "            subgraph S1[\"Session\"]\n",
    "                D1[\"Session.Events\"]\n",
    "                D2[\"Session.State\"]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "``` -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 How to manage sessions?\n",
    "\n",
    "An agentic application can have multiple users and each user may have multiple sessions with the application.\n",
    "To manage these sessions and events, ADK offers a **Session Manager** and **Runner**.\n",
    "\n",
    "1. **`SessionService`**: The storage layer\n",
    "   - Manages creation, storage, and retrieval of session data\n",
    "   - Different implementations for different needs (memory, database, cloud)\n",
    "\n",
    "2. **`Runner`**: The orchestration layer\n",
    "   - Manages the flow of information between user and agent\n",
    "   - Automatically maintains conversation history\n",
    "   - Handles the Context Engineering behind the scenes\n",
    "\n",
    "Think of it like this:\n",
    "\n",
    "- **Session** = A notebook üìì\n",
    "- **Events** = Individual entries in a single page üìù\n",
    "- **SessionService** = The filing cabinet storing notebooks üóÑÔ∏è\n",
    "- **Runner** = The assistant managing the conversation ü§ñ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Implementing Our First Stateful Agent\n",
    "\n",
    "Let's build our first stateful agent, that can remember and have constructive conversations. \n",
    "\n",
    "ADK offers different types of sessions suitable for different needs. As a start, we'll start with a simple Session Management option (`InMemorySessionService`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:43:15.637796Z",
     "iopub.status.busy": "2025-11-29T07:43:15.637469Z",
     "iopub.status.idle": "2025-11-29T07:43:15.645300Z",
     "shell.execute_reply": "2025-11-29T07:43:15.644485Z",
     "shell.execute_reply.started": "2025-11-29T07:43:15.637774Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Stateful agent initialized!\n",
      "   - Application: default\n",
      "   - User: default\n",
      "   - Using: InMemorySessionService\n"
     ]
    }
   ],
   "source": [
    "APP_NAME = \"default\"  # Application\n",
    "USER_ID = \"default\"  # User\n",
    "SESSION = \"default\"  # Session\n",
    "\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "\n",
    "# Step 1: Create the LLM Agent\n",
    "root_agent = Agent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"A text chatbot\",  # Description of the agent's purpose\n",
    ")\n",
    "\n",
    "# Step 2: Set up Session Management\n",
    "# InMemorySessionService stores conversations in RAM (temporary)\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Step 3: Create the Runner\n",
    "runner = Runner(agent=root_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "print(\"‚úÖ Stateful agent initialized!\")\n",
    "print(f\"   - Application: {APP_NAME}\")\n",
    "print(f\"   - User: {USER_ID}\")\n",
    "print(f\"   - Using: {session_service.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Testing Our Stateful Agent\n",
    "\n",
    "Now let's see the magic of sessions in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:43:33.014309Z",
     "iopub.status.busy": "2025-11-29T07:43:33.013666Z",
     "iopub.status.idle": "2025-11-29T07:43:33.728372Z",
     "shell.execute_reply": "2025-11-29T07:43:33.727588Z",
     "shell.execute_reply.started": "2025-11-29T07:43:33.014280Z"
    },
    "lines_to_next_cell": 2,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: stateful-agentic-session\n",
      "\n",
      "User > Hi, I am Anand! What is the capital of United States?\n",
      "gemini-2.5-flash-lite >  Hi Anand! The capital of the United States is Washington, D.C.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  Your name is Anand!\n"
     ]
    }
   ],
   "source": [
    "# Run a conversation with two queries in the same session\n",
    "# Notice: Both queries are part of the SAME session, so context is maintained\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\n",
    "        \"Hi, I am Anand! What is the capital of United States?\",\n",
    "        \"Hello! What is my name?\",  # This time, the agent should remember!\n",
    "    ],\n",
    "    \"stateful-agentic-session\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéâ **Success!** The agent remembered your name because both queries were part of the same session. The Runner automatically maintained the conversation history.\n",
    "\n",
    "But there's a catch: `InMemorySessionService` is temporary. **Once the application stops, all conversation history is lost.** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõë (Optional) 2.6 Testing Agent's forgetfulness\n",
    "\n",
    "> To verify that the agent forgets the conversation, **restart the kernel**. Then, **run ALL the previous cells in this notebook EXCEPT the `run_session` in 2.5.**\n",
    "> \n",
    "> Now run the cell below. You'll see that the agent doesn't remember anything from the previous conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:43:39.818968Z",
     "iopub.status.busy": "2025-11-29T07:43:39.818595Z",
     "iopub.status.idle": "2025-11-29T07:43:40.571664Z",
     "shell.execute_reply": "2025-11-29T07:43:40.570689Z",
     "shell.execute_reply.started": "2025-11-29T07:43:39.818943Z"
    },
    "lines_to_next_cell": 2,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: stateful-agentic-session\n",
      "\n",
      "User > What did I ask you about earlier?\n",
      "gemini-2.5-flash-lite >  You asked me what the capital of the United States is.\n",
      "\n",
      "User > And remind me, what's my name?\n",
      "gemini-2.5-flash-lite >  Your name is Anand!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell after restarting the kernel. All this history will be gone...\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\"What did I ask you about earlier?\", \"And remind me, what's my name?\"],\n",
    "    \"stateful-agentic-session\",\n",
    ")  # Note, we are using same session name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "Session information is not persistent (i.e., meaningful conversations are lost). While this is advantageous in testing environments, **in the real world, a user should be able to refer from past and resume conversations.** To achieve this, we must persist information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Section 3: Persistent Sessions with `DatabaseSessionService`\n",
    "\n",
    "While `InMemorySessionService` is great for prototyping, real-world applications need conversations to survive restarts, crashes, and deployments. Let's level up to persistent storage!\n",
    "\n",
    "### 3.1 Choosing the Right SessionService\n",
    "\n",
    "ADK provides different SessionService implementations for different needs:\n",
    "\n",
    "| Service | Use Case | Persistence | Best For |\n",
    "|---------|----------|-------------|----------|\n",
    "| **InMemorySessionService** | Development & Testing | ‚ùå Lost on restart | Quick prototypes |\n",
    "| **DatabaseSessionService** | Self-managed apps | ‚úÖ Survives restarts | Small to medium apps |\n",
    "| **Agent Engine Sessions** | Production on GCP | ‚úÖ Fully managed | Enterprise scale |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Implementing Persistent Sessions\n",
    "\n",
    "Let's upgrade to `DatabaseSessionService` using SQLite. This gives us persistence without needing a separate database server for this demo.\n",
    "\n",
    "Let's create a `chatbot_agent` capable of having a conversation with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:44:09.754642Z",
     "iopub.status.busy": "2025-11-29T07:44:09.754330Z",
     "iopub.status.idle": "2025-11-29T07:44:09.848801Z",
     "shell.execute_reply": "2025-11-29T07:44:09.847877Z",
     "shell.execute_reply.started": "2025-11-29T07:44:09.754619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Upgraded to persistent sessions!\n",
      "   - Database: my_agent_data.db\n",
      "   - Sessions will survive restarts!\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create the same agent (notice we use LlmAgent this time)\n",
    "chatbot_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"A text chatbot with persistent memory\",\n",
    ")\n",
    "\n",
    "# Step 2: Switch to DatabaseSessionService\n",
    "# SQLite database will be created automatically\n",
    "db_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\n",
    "session_service = DatabaseSessionService(db_url=db_url)\n",
    "\n",
    "# Step 3: Create a new runner with persistent storage\n",
    "runner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)\n",
    "\n",
    "print(\"‚úÖ Upgraded to persistent sessions!\")\n",
    "print(f\"   - Database: my_agent_data.db\")\n",
    "print(f\"   - Sessions will survive restarts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Test Run 1: Verifying Persistence\n",
    "\n",
    "In this first test run, we'll start a new conversation with the session ID `test-db-session-01`. We will first introduce our name as 'Sam' and then ask a question. In the second turn, we will ask the agent for our name.\n",
    "\n",
    "Since we are using `DatabaseSessionService`, the agent should remember the name.\n",
    "\n",
    "After the conversation, we'll inspect the `my_agent_data.db` SQLite database directly to see how the conversation `events` (the user queries and model responses) are stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:44:25.758994Z",
     "iopub.status.busy": "2025-11-29T07:44:25.758601Z",
     "iopub.status.idle": "2025-11-29T07:44:26.465057Z",
     "shell.execute_reply": "2025-11-29T07:44:26.464157Z",
     "shell.execute_reply.started": "2025-11-29T07:44:25.758958Z"
    },
    "lines_to_next_cell": 2,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-01\n",
      "\n",
      "User > Hi, I am Anand! What is the capital of the United States?\n",
      "gemini-2.5-flash-lite >  Hi Anand! The capital of the United States is Washington, D.C.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  Your name is Anand.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner,\n",
    "    [\"Hi, I am Anand! What is the capital of the United States?\", \"Hello! What is my name?\"],\n",
    "    \"test-db-session-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõë (Optional) 3.4 Test Run 2: Resuming a Conversation\n",
    "\n",
    "> ‚ÄºÔ∏è Now, let's repeat the test again, but this time, **let's stop this Kaggle Notebook's kernel and restart it again.**\n",
    ">\n",
    "> 1. Run all the previous cells in the notebook, **EXCEPT** the previous Section 3.3 (`run_session` cell).\n",
    ">\n",
    "> 2. Now, run the below cell with the **same session ID** (`test-db-session-01`).\n",
    "\n",
    "We will ask a new question and then ask for our name again. **Because the session is loaded from the database, the agent should still remember** that our name is 'Sam' from the first test run. This demonstrates the power of persistent sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:44:33.288932Z",
     "iopub.status.busy": "2025-11-29T07:44:33.288311Z",
     "iopub.status.idle": "2025-11-29T07:44:34.076181Z",
     "shell.execute_reply": "2025-11-29T07:44:34.075330Z",
     "shell.execute_reply.started": "2025-11-29T07:44:33.288899Z"
    },
    "lines_to_next_cell": 2,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-01\n",
      "\n",
      "User > What is the capital of India?\n",
      "gemini-2.5-flash-lite >  The capital of India is New Delhi.\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  Your name is Anand.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner,\n",
    "    [\"What is the capital of India?\", \"Hello! What is my name?\"],\n",
    "    \"test-db-session-01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Let's verify that the session data is isolated\n",
    "\n",
    "As mentioned earlier, a session is private conversation between an Agent and a User (i.e., two sessions do not share information). Let's run our `run_session` with a different session name `test-db-session-02` to confirm this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:44:36.883142Z",
     "iopub.status.busy": "2025-11-29T07:44:36.882501Z",
     "iopub.status.idle": "2025-11-29T07:44:37.352429Z",
     "shell.execute_reply": "2025-11-29T07:44:37.351582Z",
     "shell.execute_reply.started": "2025-11-29T07:44:36.883112Z"
    },
    "lines_to_next_cell": 2,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: test-db-session-02\n",
      "\n",
      "User > Hello! What is my name?\n",
      "gemini-2.5-flash-lite >  I do not have access to your personal information, including your name. Therefore, I cannot tell you what your name is.\n"
     ]
    }
   ],
   "source": [
    "await run_session(\n",
    "    runner, [\"Hello! What is my name?\"], \"test-db-session-02\"\n",
    ")  # Note, we are using new session name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 How are the events stored in the Database?\n",
    "\n",
    "Since we are using a sqlite DB to store information, let's have a quick peek to see how information is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:44:47.221270Z",
     "iopub.status.busy": "2025-11-29T07:44:47.220557Z",
     "iopub.status.idle": "2025-11-29T07:44:47.228340Z",
     "shell.execute_reply": "2025-11-29T07:44:47.227501Z",
     "shell.execute_reply.started": "2025-11-29T07:44:47.221244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['app_name', 'session_id', 'author', 'content']\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hi, I am Sam! What is the capital of the United States?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Hi Sam! The capital of the United States is Washington, D.C.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Sam.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hi, I am Anand! What is the capital of the United States?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Hi Anand! The capital of the United States is Washington, D.C.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Anand.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"What is the capital of India?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"The capital of India is New Delhi.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-01', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-01', 'text_chat_bot', '{\"parts\": [{\"text\": \"Your name is Anand.\"}], \"role\": \"model\"}')\n",
      "('default', 'test-db-session-02', 'user', '{\"parts\": [{\"text\": \"Hello! What is my name?\"}], \"role\": \"user\"}')\n",
      "('default', 'test-db-session-02', 'text_chat_bot', '{\"parts\": [{\"text\": \"I do not have access to your personal information, including your name. Therefore, I cannot tell you what your name is.\"}], \"role\": \"model\"}')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def check_data_in_db():\n",
    "    with sqlite3.connect(\"my_agent_data.db\") as connection:\n",
    "        cursor = connection.cursor()\n",
    "        result = cursor.execute(\n",
    "            \"select app_name, session_id, author, content from events\"\n",
    "        )\n",
    "        print([_[0] for _ in result.description])\n",
    "        for each in result.fetchall():\n",
    "            print(each)\n",
    "\n",
    "\n",
    "check_data_in_db()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚è≥ Section 4: Context Compaction\n",
    "\n",
    "As you can see, all the events are stored in full in the session Database, and this quickly adds up. For a long, complex task, this list of events can become very large, leading to slower performance and higher costs.\n",
    "\n",
    "But what if we could automatically summarize the past? Let's use ADK's **Context Compaction** feature to see **how to automatically reduce the context that's stored in the Session.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/context-compaction.png\" width=\"1400\" alt=\"Context compaction\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create an App for the agent\n",
    "\n",
    "To enable this feature, let's use the same `chatbot_agent` we created in Section 3.2. \n",
    "\n",
    "The first step is to create an object called `App`. We'll give it a name and pass in our chatbot_agent. \n",
    "\n",
    "We'll also create a new config to do the Context Compaction. This **`EventsCompactionConfig`** defines two key variables:\n",
    "\n",
    "- **compaction_interval**: Asks the Runner to compact the history after every `n` conversations\n",
    "- **overlap_size**: Defines the number of previous conversations to retain for overlap\n",
    "\n",
    "We'll then provide this app to the Runner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:45:10.344494Z",
     "iopub.status.busy": "2025-11-29T07:45:10.344149Z",
     "iopub.status.idle": "2025-11-29T07:45:10.354289Z",
     "shell.execute_reply": "2025-11-29T07:45:10.352998Z",
     "shell.execute_reply.started": "2025-11-29T07:45:10.344471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Research App upgraded with Events Compaction!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47/3773147741.py:6: UserWarning: [EXPERIMENTAL] EventsCompactionConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  events_compaction_config=EventsCompactionConfig(\n"
     ]
    }
   ],
   "source": [
    "# Re-define our app with Events Compaction enabled\n",
    "research_app_compacting = App(\n",
    "    name=\"research_app_compacting\",\n",
    "    root_agent=chatbot_agent,\n",
    "    # This is the new part!\n",
    "    events_compaction_config=EventsCompactionConfig(\n",
    "        compaction_interval=3,  # Trigger compaction every 3 invocations\n",
    "        overlap_size=1,  # Keep 1 previous turn for context\n",
    "    ),\n",
    ")\n",
    "\n",
    "db_url = \"sqlite:///my_agent_data.db\"  # Local SQLite file\n",
    "session_service = DatabaseSessionService(db_url=db_url)\n",
    "\n",
    "# Create a new runner for our upgraded app\n",
    "research_runner_compacting = Runner(\n",
    "    app=research_app_compacting, session_service=session_service\n",
    ")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Research App upgraded with Events Compaction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Running the Demo\n",
    "\n",
    "Now, let's have a conversation that is long enough to trigger the compaction. When you run the cell below, the output will look like a normal conversation. However, because we configured our `App`, a compaction process will run silently in the background after the 3rd invocation.\n",
    "\n",
    "In the next step, we'll prove that it happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:45:21.468973Z",
     "iopub.status.busy": "2025-11-29T07:45:21.468620Z",
     "iopub.status.idle": "2025-11-29T07:45:44.648091Z",
     "shell.execute_reply": "2025-11-29T07:45:44.647313Z",
     "shell.execute_reply.started": "2025-11-29T07:45:21.468947Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > What is the latest news about AI in healthcare?\n",
      "gemini-2.5-flash-lite >  Here's a summary of some of the latest news and trends in AI in healthcare:\n",
      "\n",
      "**Key Areas of Advancement and News:**\n",
      "\n",
      "*   **Drug Discovery and Development:** This remains a hot area. Companies are using AI to:\n",
      "    *   **Identify novel drug targets:** AI can analyze vast biological datasets to pinpoint proteins or pathways that could be targeted for new therapies.\n",
      "    *   **Design new molecules:** Generative AI models are being used to create entirely new drug compounds with desired properties, potentially speeding up the early stages of drug development.\n",
      "    *   **Predict drug efficacy and safety:** AI algorithms can analyze clinical trial data and patient profiles to better predict how a drug will perform and identify potential side effects.\n",
      "    *   **News Highlights:** Look for announcements from major pharmaceutical companies (Pfizer, Moderna, Novartis, etc.) and specialized AI drug discovery firms about new drug candidates entering trials or partnerships.\n",
      "\n",
      "*   **Diagnostic Imaging and Pathology:** AI continues to make significant strides in interpreting medical images.\n",
      "    *   **Radiology:** AI tools are assisting radiologists in detecting subtle abnormalities in X-rays, CT scans, and MRIs, potentially improving accuracy and speed for conditions like cancer, stroke, and diabetic retinopathy.\n",
      "    *   **Pathology:** AI is being used to analyze digital pathology slides, helping pathologists identify cancerous cells, grade tumors, and predict patient outcomes.\n",
      "    *   **News Highlights:** Regulatory approvals (like FDA clearances) for new AI-powered diagnostic software are frequently announced. Companies like Viz.ai (stroke detection) and Paige (pathology) are often in the news.\n",
      "\n",
      "*   **Personalized Medicine and Treatment Planning:** AI is enabling more tailored healthcare approaches.\n",
      "    *   **Genomic Analysis:** AI can analyze complex genomic data to identify genetic predispositions to diseases and predict individual responses to treatments.\n",
      "    *   **Treatment Optimization:** AI can help oncologists, for example, select the most effective treatment plans for individual cancer patients based on their tumor's genetic makeup, clinical history, and other factors.\n",
      "    *   **News Highlights:** Research papers and clinical trial results demonstrating the effectiveness of AI-guided personalized treatments are emerging.\n",
      "\n",
      "*   **AI-Powered Medical Devices and Wearables:**\n",
      "    *   **Remote Patient Monitoring:** AI algorithms are analyzing data from wearables and home monitoring devices to detect early signs of deterioration or complications in patients with chronic conditions, allowing for timely interventions.\n",
      "    *   **Surgical Robotics:** AI is being integrated into robotic surgical systems to enhance precision, provide real-time guidance to surgeons, and potentially automate certain surgical tasks.\n",
      "    *   **News Highlights:** New product launches and partnerships between tech companies and healthcare providers are common.\n",
      "\n",
      "*   **Administrative and Operational Efficiency:** AI is also being deployed to streamline back-end processes in healthcare.\n",
      "    *   **Automating tasks:** AI can handle tasks like medical coding, appointment scheduling, and prior authorization, freeing up healthcare professionals.\n",
      "    *   **Predictive analytics:** AI can forecast patient flow, optimize staffing, and manage hospital resources more effectively.\n",
      "    *   **News Highlights:** Health systems are reporting on pilot programs and successful implementations of AI for administrative improvements.\n",
      "\n",
      "*   **Generative AI (Large Language Models - LLMs):** This is a major buzzword, with applications like:\n",
      "    *   **Clinical Documentation:** AI assistants can help draft clinical notes, summarize patient histories, and generate discharge instructions.\n",
      "    *   **Medical Education and Training:** LLMs can be used to create realistic patient scenarios for training medical students and professionals.\n",
      "    *   **Patient Communication:** AI-powered chatbots can answer patient questions, provide information about conditions, and help with appointment booking.\n",
      "    *   **News Highlights:** Companies are developing LLMs specifically trained on medical literature and data (e.g., Google's Med-PaLM 2) and are exploring their integration into EHR systems and other clinical workflows.\n",
      "\n",
      "**Challenges and Considerations:**\n",
      "\n",
      "Despite the progress, several challenges remain:\n",
      "\n",
      "*   **Data Privacy and Security:** Ensuring patient data is protected is paramount.\n",
      "*   **Regulatory Hurdles:** AI in healthcare is subject to strict regulations, and obtaining approvals can be a lengthy process.\n",
      "*   **Bias in AI Models:** AI models can inherit biases from the data they are trained on, potentially leading to disparities in care.\n",
      "*   **Integration into Existing Workflows:** Seamlessly integrating AI tools into busy clinical settings can be complex.\n",
      "*   **Clinician Adoption and Trust:** Building trust and ensuring healthcare professionals understand and adopt AI tools is crucial for success.\n",
      "\n",
      "**Where to find the latest news:**\n",
      "\n",
      "*   **Reputable Tech and Healthcare News Outlets:** FierceBiotech, STAT News, TechCrunch (healthcare section), Nature Medicine, JAMA, The Lancet.\n",
      "*   **Industry Conferences:** HIMSS, RSNA, HLTH, and various AI in healthcare specific conferences often feature major announcements.\n",
      "*   **Company Press Releases:** Follow major tech companies (Google, Microsoft, Amazon) and healthcare/pharma giants, as well as specialized AI healthcare startups.\n",
      "\n",
      "To get the *absolute latest*, I'd recommend checking these sources regularly, as the field is moving incredibly fast!\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Are there any new developments in drug discovery?\n",
      "gemini-2.5-flash-lite >  Yes, absolutely! Drug discovery is one of the most dynamic and rapidly evolving areas of AI in healthcare. Here are some of the newest and most exciting developments:\n",
      "\n",
      "**1. Generative AI for Novel Molecule Design:**\n",
      "\n",
      "*   **The Concept:** Instead of just screening existing libraries of compounds, generative AI models (like those based on GANs, VAEs, and transformer architectures) can **create entirely new molecular structures** from scratch that are optimized for specific properties.\n",
      "*   **What's New:**\n",
      "    *   **\"De Novo\" Design:** AI is moving beyond simple modifications of existing drugs to designing molecules with novel scaffolds and mechanisms of action.\n",
      "    *   **Multi-Objective Optimization:** Models are getting better at simultaneously designing molecules that are not only potent against a target but also have good ADMET properties (Absorption, Distribution, Metabolism, Excretion, Toxicity) and are synthetically feasible.\n",
      "    *   **Targeted Generation:** AI can be instructed to design molecules that bind to a specific protein pocket or interact with a particular biological pathway, making the process much more precise.\n",
      "*   **Examples:** Companies like **Recursion Pharmaceuticals**, **Exscientia**, and **Insilico Medicine** are at the forefront, often announcing collaborations with Big Pharma and the progression of AI-designed drug candidates into clinical trials.\n",
      "\n",
      "**2. AI for Protein Structure Prediction and Design:**\n",
      "\n",
      "*   **The Breakthrough:** While not strictly \"drug discovery,\" accurate protein structure prediction is a *precursor* to it. AlphaFold (DeepMind/Google) revolutionized this by predicting the 3D structure of proteins with unprecedented accuracy.\n",
      "*   **What's New in Drug Discovery Context:**\n",
      "    *   **Target Identification:** Knowing the structure of disease-related proteins helps researchers identify druggable sites.\n",
      "    *   **Structure-Based Drug Design:** AI can now use these predicted structures to virtually screen millions of potential drug molecules and predict how they'll bind, or even design molecules specifically to fit into these predicted structures.\n",
      "    *   **Protein Design:** Emerging AI models are also learning to **design novel proteins** with specific functions, which could lead to new biologics or enzymes for therapeutic use.\n",
      "\n",
      "**3. AI in Identifying New Drug Targets and Disease Mechanisms:**\n",
      "\n",
      "*   **The Concept:** AI excels at finding patterns in massive, complex datasets that humans might miss.\n",
      "*   **What's New:**\n",
      "    *   **Multi-omics Integration:** AI can integrate data from genomics, transcriptomics, proteomics, metabolomics, and clinical records to uncover subtle relationships and identify novel therapeutic targets for complex diseases like Alzheimer's, autoimmune disorders, and various cancers.\n",
      "    *   **Causal Inference:** Advanced AI techniques are moving towards understanding causal relationships in biological systems, helping to pinpoint the most effective targets for intervention rather than just correlative ones.\n",
      "    *   **\"Undruggable\" Targets:** AI is being applied to explore strategies for targeting proteins previously considered too difficult to drug.\n",
      "\n",
      "**4. Accelerating Pre-clinical and Clinical Trials:**\n",
      "\n",
      "*   **The Concept:** AI isn't just about finding molecules; it's also about speeding up the journey to the patient.\n",
      "*   **What's New:**\n",
      "    *   **Predicting Trial Success:** AI can analyze historical trial data and patient characteristics to predict the likelihood of success for a new drug candidate in clinical trials.\n",
      "    *   **Optimizing Trial Design:** AI can help design more efficient clinical trials by identifying optimal patient populations, endpoints, and trial sites.\n",
      "    *   **Biomarker Discovery:** AI can identify novel biomarkers from patient data that can predict drug response or disease progression, aiding in patient stratification.\n",
      "    *   **Drug Repurposing:** AI can analyze vast databases of existing drugs and their known effects to identify potential new uses for them against different diseases, a much faster route than developing new drugs from scratch.\n",
      "\n",
      "**5. \"Lab Automation on Steroids\" - AI-Driven Synthesis and Experimentation:**\n",
      "\n",
      "*   **The Concept:** Connecting AI with robotic lab systems to create closed-loop drug discovery.\n",
      "*   **What's New:**\n",
      "    *   **Autonomous Laboratories:** AI algorithms guide robotic arms to perform chemical synthesis and biological assays. The AI analyzes the results, learns from them, and then designs the next experiment, creating a continuous cycle of learning and discovery without human intervention.\n",
      "    *   **Rapid Iteration:** This dramatically speeds up the process of testing and refining candidate molecules.\n",
      "\n",
      "**Key Players and Trends to Watch:**\n",
      "\n",
      "*   **AI-Native Biotech Companies:** Exscientia, Recursion, Insilico Medicine, Relay Therapeutics, AbCellera, Schr√∂dinger.\n",
      "*   **Big Pharma Partnerships:** Major pharmaceutical companies are increasingly partnering with or acquiring AI-driven biotech firms to integrate these capabilities.\n",
      "*   **Focus on Specific Modalities:** While small molecules are a major focus, AI is also being applied to antibody discovery, gene therapies, and RNA therapeutics.\n",
      "\n",
      "In summary, the drug discovery landscape is being reshaped by AI's ability to generate novel hypotheses, design complex molecules, predict biological outcomes, and automate experimental processes at an unprecedented scale and speed.\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Tell me more about the second development you found.\n",
      "gemini-2.5-flash-lite >  Okay, let's dive deeper into the second development I mentioned: **AI for Protein Structure Prediction and Design**, and its impact on drug discovery.\n",
      "\n",
      "This is a truly groundbreaking area, fundamentally changing how we understand and interact with the building blocks of life.\n",
      "\n",
      "**The Core Idea: Proteins are the Workhorses of Biology**\n",
      "\n",
      "Proteins are the molecules that do most of the heavy lifting in cells. They act as enzymes, transporters, structural components, signaling molecules, and much more. Their function is intimately tied to their **3D shape (structure)**. If you don't know the shape of a protein, it's very hard to design a drug that can interact with it effectively.\n",
      "\n",
      "**The Historical Challenge: Determining Protein Structure is Hard**\n",
      "\n",
      "For decades, determining a protein's 3D structure was a laborious and expensive process. It typically involved:\n",
      "\n",
      "*   **Purifying large quantities of the protein.**\n",
      "*   **Crystallizing it** (getting it to form a perfect, ordered crystal lattice), which is often impossible for many proteins.\n",
      "*   **Using X-ray crystallography or cryo-electron microscopy (cryo-EM)** to determine the electron density and then build a structural model.\n",
      "\n",
      "This process could take years and often failed, leaving many important proteins with unknown structures.\n",
      "\n",
      "**The AI Revolution: AlphaFold and its Successors**\n",
      "\n",
      "*   **AlphaFold (DeepMind/Google):** This was the game-changer. AlphaFold is an AI system that can predict the 3D structure of a protein from its amino acid sequence with astonishing accuracy, often comparable to experimentally determined structures.\n",
      "    *   **How it works (simplified):** It uses deep learning techniques, specifically a form of \"attention\" network (similar to those used in language translation), to analyze evolutionary relationships between amino acids in a sequence. Amino acids that are far apart in the sequence but close together in the 3D structure tend to co-evolve. AlphaFold learns these patterns and uses them to predict distances between amino acids, which then allows it to fold the protein into its most likely 3D conformation.\n",
      "    *   **Impact:** The release of AlphaFold's predictions for over 200 million proteins in the public domain (via the AlphaFold Protein Structure Database) was a monumental event. It essentially democratized structural biology.\n",
      "\n",
      "**How This Directly Fuels Drug Discovery:**\n",
      "\n",
      "1.  **Identifying Druggable Targets:**\n",
      "    *   **Previously \"Undruggable\" Proteins:** Now that we have structures for millions of proteins, researchers can examine them for specific \"pockets\" or active sites where a small molecule drug could bind and modulate its activity. Many targets previously thought to be undruggable are now being revisited.\n",
      "    *   **Understanding Disease Mechanisms:** Knowing the structure of a protein involved in a disease allows scientists to understand *how* it malfunctions. Is it misfolded? Is it overactive? Is it interacting with the wrong partners? This insight is crucial for designing interventions.\n",
      "\n",
      "2.  **Structure-Based Drug Design (SBDD):**\n",
      "    *   **Virtual Screening:** With an accurate protein structure, computational chemists can virtually screen massive libraries of existing drug-like molecules to see which ones are predicted to bind to the target. This is much faster and cheaper than physically testing every compound.\n",
      "    *   **Rational Drug Design:** AI can go beyond screening. It can be used to design *new* molecules from scratch that are predicted to fit perfectly into the binding site of the target protein, maximizing potency and minimizing off-target effects. This is where AI-driven generative chemistry (mentioned in point 1) truly shines, now with precise structural information to guide it.\n",
      "    *   **Optimizing Binding:** AI can help predict how small modifications to a lead compound might improve its binding affinity, selectivity, and pharmacokinetic properties.\n",
      "\n",
      "3.  **Understanding Drug Resistance:**\n",
      "    *   **Mutations:** Many diseases, especially cancers and infections, develop resistance to drugs through mutations that alter the target protein's structure. AI can predict how these mutations change the protein's shape and, therefore, how the drug interacts with it, helping to design next-generation drugs that overcome resistance.\n",
      "\n",
      "4.  **Designing Novel Biologics (Antibodies, Peptides):**\n",
      "    *   **Targeting Specific Epitopes:** AI can help design antibodies or peptides that bind to very specific regions (epitopes) on a protein surface, ensuring high specificity and potentially reduced side effects.\n",
      "    *   **Engineering Protein Function:** Beyond just blocking proteins, AI is now being used to design *entirely new* proteins with desired therapeutic functions, such as enzymes that degrade a specific molecule or proteins that can deliver payloads.\n",
      "\n",
      "**What's Next?**\n",
      "\n",
      "*   **Dynamic Structures:** While AlphaFold predicts a static structure, proteins are dynamic and change shape. AI is now moving towards predicting protein *dynamics* and how they change upon binding to ligands (drugs).\n",
      "*   **Protein-Protein Interactions:** Predicting how proteins interact with each other is another complex area where AI is making strides, crucial for understanding cellular pathways.\n",
      "*   **AI-Designed Proteins:** The ability to design entirely new functional proteins opens up vast therapeutic possibilities.\n",
      "\n",
      "In essence, AlphaFold and similar AI advancements have provided a detailed structural map of the biological universe. Drug discovery can now leverage this map with unprecedented precision and speed, moving from a process of educated guessing and extensive screening to one that is increasingly rational, predictive, and data-driven.\n",
      "\n",
      " ### Session: compaction_demo\n",
      "\n",
      "User > Who are the main companies involved in that?\n",
      "gemini-2.5-flash-lite >  You're right to ask about the companies! While the foundational breakthroughs in protein structure prediction were often academic or from large research labs, the *application* and *commercialization* of these tools in drug discovery are driven by a mix of companies.\n",
      "\n",
      "Here's a breakdown of the main players involved in leveraging AI for protein structure prediction and design in drug discovery:\n",
      "\n",
      "**1. The Pioneers of AI Prediction Models (Foundational Work):**\n",
      "\n",
      "*   **Google / DeepMind:**\n",
      "    *   **Key Contribution:** **AlphaFold**. Their development of AlphaFold2 was a watershed moment, dramatically improving the accuracy and accessibility of protein structure prediction.\n",
      "    *   **In Drug Discovery:** While DeepMind's primary focus is AI research, they have begun to explore drug discovery applications themselves, particularly through partnerships and their own internal projects. They released AlphaFold's predictions publicly, which has been a massive boon to the entire field.\n",
      "\n",
      "*   **NVIDIA:**\n",
      "    *   **Key Contribution:** While not developing prediction algorithms themselves in the same way as DeepMind, NVIDIA provides the **essential hardware (GPUs) and software platforms (like CUDA, Clara)** that make training and running these massive AI models computationally feasible. They also actively contribute to AI research and have initiatives focused on scientific discovery. Their **BioNeMo** platform aims to provide AI models and tools for drug discovery, including those related to protein structure.\n",
      "\n",
      "**2. AI-Native Drug Discovery Companies (Leveraging Prediction for Design):**\n",
      "\n",
      "These companies were often built from the ground up with AI at their core, and they heavily utilize (or have developed their own versions of) structure prediction tools.\n",
      "\n",
      "*   **Schr√∂dinger:**\n",
      "    *   **Key Contribution:** A long-standing leader in computational chemistry, Schr√∂dinger has been integrating AI and machine learning with their sophisticated physics-based modeling for years. They use protein structure prediction as a critical input for their highly accurate **drug design and optimization platform**. They offer both software solutions and run their own drug discovery programs.\n",
      "\n",
      "*   **Exscientia:**\n",
      "    *   **Key Contribution:** Known for its AI-driven drug design platform that uses generative AI and reinforcement learning. They integrate protein structure prediction (often using AlphaFold or proprietary methods) to design novel molecules that bind to specific protein targets. They have several AI-designed drug candidates in clinical trials.\n",
      "\n",
      "*   **Relay Therapeutics:**\n",
      "    *   **Key Contribution:** Focuses on understanding protein motion and \"allostery\" (how binding at one site affects another). They combine experimental techniques (like mass spectrometry) with AI and physics-based modeling to study protein dynamics and how drugs interact with these dynamic structures. Their work inherently relies on accurate structural information, including predictions.\n",
      "\n",
      "*   **Atomwise:**\n",
      "    *   **Key Contribution:** Specializes in using deep learning for small molecule drug discovery, particularly for **virtual screening**. They use AI to predict how small molecules will bind to protein targets, and accurate structural information (whether predicted or experimental) is crucial for their algorithms.\n",
      "\n",
      "*   **Cresset Bio:**\n",
      "    *   **Key Contribution:** Develops AI-powered platforms for drug discovery, with a strong emphasis on **computational chemistry and molecular modeling**. They leverage protein structures (including predicted ones) to design and optimize novel molecules.\n",
      "\n",
      "*   **Insilico Medicine:**\n",
      "    *   **Key Contribution:** Uses AI for target identification, molecular design, and predicting clinical trial outcomes. Protein structure prediction is a fundamental component of their generative chemistry engine.\n",
      "\n",
      "**3. Traditional Pharmaceutical Companies (Adopting and Partnering):**\n",
      "\n",
      "Major pharmaceutical companies are not just waiting around; they are actively acquiring, partnering with, and developing their own internal capabilities in AI-driven structural biology.\n",
      "\n",
      "*   **Pfizer, Novartis, AstraZeneca, Merck, etc.:** These companies are investing heavily in building AI teams and capabilities. They partner with AI-native biotechs, acquire promising technologies, and develop internal platforms that integrate protein structure prediction (often using AlphaFold or similar tools) into their R&D pipelines. They use these tools for target validation, lead optimization, and more.\n",
      "\n",
      "**4. Database and Resource Providers:**\n",
      "\n",
      "*   **The European Molecular Biology Laboratory (EMBL) - European Bioinformatics Institute (EMBL-EBI):** Hosts the **AlphaFold Protein Structure Database**, making the predicted structures freely available to researchers worldwide. This is a crucial resource that enables many of the companies listed above.\n",
      "*   **The Protein Data Bank (PDB):** While not an AI company, the PDB is the archive for experimentally determined protein structures. AI prediction tools are often validated against PDB data, and AI-generated structures can complement and expand upon the PDB's offerings.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "The landscape involves:\n",
      "*   **AI Research Giants** (like Google/DeepMind) providing the foundational predictive models.\n",
      "*   **Hardware providers** (like NVIDIA) enabling the computational power.\n",
      "*   **AI-native biotechs** (Schr√∂dinger, Exscientia, Relay) building entire drug discovery platforms around these predictions.\n",
      "*   **Big Pharma** integrating these advanced tools and forging partnerships.\n",
      "\n",
      "The open-source nature of AlphaFold's predictions has been a massive accelerant, empowering a wide range of players to enter and innovate in this space.\n"
     ]
    }
   ],
   "source": [
    "# Turn 1\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"What is the latest news about AI in healthcare?\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 2\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Are there any new developments in drug discovery?\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 3 - Compaction should trigger after this turn!\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Tell me more about the second development you found.\",\n",
    "    \"compaction_demo\",\n",
    ")\n",
    "\n",
    "# Turn 4\n",
    "await run_session(\n",
    "    research_runner_compacting,\n",
    "    \"Who are the main companies involved in that?\",\n",
    "    \"compaction_demo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Verifying Compaction in the Session History\n",
    "\n",
    "The conversation above looks normal, but the history has been changed behind the scenes. How can we prove it?\n",
    "\n",
    "We can inspect the `events` list from our session. The compaction process **doesn't delete old events; it replaces them with a single, new `Event` that contains the summary.** Let's find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:45:44.649376Z",
     "iopub.status.busy": "2025-11-29T07:45:44.649070Z",
     "iopub.status.idle": "2025-11-29T07:45:44.662680Z",
     "shell.execute_reply": "2025-11-29T07:45:44.661718Z",
     "shell.execute_reply.started": "2025-11-29T07:45:44.649349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Searching for Compaction Summary Event ---\n",
      "\n",
      "‚úÖ SUCCESS! Found the Compaction Event:\n",
      "  Author: user\n",
      "\n",
      " Compacted information: model_version=None content=None grounding_metadata=None partial=None turn_complete=None finish_reason=None error_code=None error_message=None interrupted=None custom_metadata=None usage_metadata=None live_session_resumption_update=None input_transcription=None output_transcription=None avg_logprobs=None logprobs_result=None cache_metadata=None citation_metadata=None invocation_id='06faddcf-4c1e-43ff-a7dd-f6b21f1fb072' author='user' actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction={'start_timestamp': 1764402321.498336, 'end_timestamp': 1764402331.972753, 'compacted_content': {'parts': [{'function_call': None, 'code_execution_result': None, 'executable_code': None, 'file_data': None, 'function_response': None, 'inline_data': None, 'text': 'The user inquired about the latest news in AI in healthcare. The AI agent provided a comprehensive overview, highlighting advancements in drug discovery, diagnostic imaging, personalized medicine, medical devices, administrative efficiency, and the emerging role of generative AI. The agent also outlined key challenges such as data privacy, regulatory hurdles, bias, integration, and clinician adoption.\\n\\nSubsequently, the user specifically asked for more details on developments in drug discovery. The AI agent elaborated on several new and exciting trends, including:\\n\\n*   **Generative AI for Novel Molecule Design:** AI creating entirely new molecular structures optimized for specific properties, moving towards novel scaffolds and mechanisms.\\n*   **AI for Protein Structure Prediction and Design:** Revolutionized by AlphaFold, enabling accurate prediction of protein structures, which is crucial for identifying druggable targets and structure-based drug design.\\n*   **AI in Identifying New Drug Targets and Disease Mechanisms:** AI\\'s ability to integrate multi-omics data to uncover complex relationships and identify novel therapeutic targets.\\n*   **Accelerating Pre-clinical and Clinical Trials:** AI predicting trial success, optimizing trial design, and aiding in biomarker discovery and drug repurposing.\\n*   **\"Lab Automation on Steroids\" - AI-Driven Synthesis and Experimentation:** Creating autonomous laboratories where AI guides robotic systems for continuous learning and discovery.\\n\\nThe user then requested further information on the second development mentioned: **AI for Protein Structure Prediction and Design**. The AI agent explained that proteins are fundamental to biological function and their 3D shape dictates their activity. Historically, determining protein structure was challenging and time-consuming. AlphaFold\\'s breakthrough in accurately predicting protein structures from amino acid sequences has been transformative.\\n\\nThe agent detailed how this advancement directly impacts drug discovery by:\\n\\n*   **Identifying Druggable Targets:** Enabling exploration of previously \"undruggable\" proteins and understanding disease mechanisms.\\n*   **Structure-Based Drug Design (SBDD):** Facilitating virtual screening of existing molecules and rational design of new ones to fit target protein binding sites.\\n*   **Understanding Drug Resistance:** Predicting how mutations alter protein structures and affect drug interactions.\\n*   **Designing Novel Biologics:** Helping to design antibodies and peptides with high specificity, and even engineering entirely new functional proteins.\\n\\nThe conversation concluded with the AI agent mentioning future directions in AI for protein structure, including predicting protein dynamics and interactions, and designing novel proteins.\\n\\n**Key Information and Decisions:**\\n\\n*   The AI provided a broad overview of AI in healthcare.\\n*   The AI detailed specific advancements in AI-driven drug discovery.\\n*   The AI explained the significance of protein structure prediction (e.g., AlphaFold) for drug discovery.\\n*   The AI outlined how protein structure prediction aids in target identification, drug design, understanding resistance, and designing biologics.\\n\\n**Unresolved Questions or Tasks:**\\n\\n*   None. The user\\'s questions were addressed with detailed explanations. The conversation naturally flowed from a broad inquiry to specific details.', 'thought': None, 'thought_signature': None, 'video_metadata': None}], 'role': 'model'}}, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None) long_running_tool_ids=set() branch=None id='3a0335a6-475b-4784-ac34-9979076279cc' timestamp=1764402341.258019\n"
     ]
    }
   ],
   "source": [
    "# Get the final session state\n",
    "final_session = await session_service.get_session(\n",
    "    app_name=research_runner_compacting.app_name,\n",
    "    user_id=USER_ID,\n",
    "    session_id=\"compaction_demo\",\n",
    ")\n",
    "\n",
    "print(\"--- Searching for Compaction Summary Event ---\")\n",
    "found_summary = False\n",
    "for event in final_session.events:\n",
    "    # Compaction events have a 'compaction' attribute\n",
    "    if event.actions and event.actions.compaction:\n",
    "        print(\"\\n‚úÖ SUCCESS! Found the Compaction Event:\")\n",
    "        print(f\"  Author: {event.author}\")\n",
    "        print(f\"\\n Compacted information: {event}\")\n",
    "        found_summary = True\n",
    "        break\n",
    "\n",
    "if not found_summary:\n",
    "    print(\n",
    "        \"\\n‚ùå No compaction event found. Try increasing the number of turns in the demo.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 What you've accomplished: Automatic Context Management\n",
    "\n",
    "You just found the proof! The presence of that special summary `Event` in your session's history is the tangible result of the compaction process.\n",
    "\n",
    "**Let's recap what you just witnessed:**\n",
    "\n",
    "1.  **Silent Operation**: You ran a standard conversation, and from the outside, nothing seemed different.\n",
    "2.  **Background Compaction**: Because you configured the `App` with `EventsCompactionConfig`, the ADK `Runner` automatically monitored the conversation length. Once the threshold was met, it triggered the summarization process in the background.\n",
    "3.  **Verified Result**: By inspecting the session's events, you found the summary that the LLM generated. This summary now replaces the older, more verbose turns in the agent's active context.\n",
    "\n",
    "**For all future turns in this conversation, the agent will be given this concise summary instead of the full history.** This saves costs, improves performance, and helps the agent stay focused on what's most important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 More Context Engineering options in ADK\n",
    "\n",
    "#### üëâ Custom Compaction\n",
    "In this example, we used ADK's default summarizer. For more advanced use cases, you can provide your own by defining a custom `SlidingWindowCompactor` and passing it to the config. This allows you to control the summarization prompt or even use a different, specialized LLM for the task. You can read more about it in the [official documentation](https://google.github.io/adk-docs/context/compaction/).\n",
    "\n",
    "#### üëâ Context Caching\n",
    "ADK also provides **Context Caching** to help reduce the token size of the static instructions that are fed to the LLM by caching the request data. Read more about it [here](https://google.github.io/adk-docs/context/caching/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem\n",
    "\n",
    "While we can do Context Compaction and use a database to resume a session, we face new challenges now. In some cases, **we have key information or preferences that we want to share across other sessions.** \n",
    "\n",
    "In these scenarios, instead of sharing the entire session history, transferring information from a few key variables can improve the session experience. Let's see how to do it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ù Section 5: Working with Session State\n",
    "\n",
    "### 5.1 Creating custom tools for Session state management\n",
    "\n",
    "Let's explore how to manually manage session state through custom tools. In this example, we'll identify a **transferable characteristic**, like a user's name and their country, and create tools to capture and save it.\n",
    "\n",
    "**Why This Example?**\n",
    "\n",
    "The username is a perfect example of information that:\n",
    "\n",
    "- Is introduced once but referenced multiple times\n",
    "- Should persist throughout a conversation\n",
    "- Represents a user-specific characteristic that enhances personalization\n",
    "\n",
    "Here, for demo purposes, we'll create two tools that can store and retrieve user name and country from the Session State. **Note that all tools have access to the `ToolContext` object.** You don't have to create separate tools for each piece of information you want to share. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:45:52.524772Z",
     "iopub.status.busy": "2025-11-29T07:45:52.524458Z",
     "iopub.status.idle": "2025-11-29T07:45:52.532520Z",
     "shell.execute_reply": "2025-11-29T07:45:52.531409Z",
     "shell.execute_reply.started": "2025-11-29T07:45:52.524747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools created.\n"
     ]
    }
   ],
   "source": [
    "# Define scope levels for state keys (following best practices)\n",
    "USER_NAME_SCOPE_LEVELS = (\"temp\", \"user\", \"app\")\n",
    "\n",
    "\n",
    "# This demonstrates how tools can write to session state using tool_context.\n",
    "# The 'user:' prefix indicates this is user-specific data.\n",
    "def save_userinfo(\n",
    "    tool_context: ToolContext, user_name: str, country: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Tool to record and save user name and country in session state.\n",
    "\n",
    "    Args:\n",
    "        user_name: The username to store in session state\n",
    "        country: The name of the user's country\n",
    "    \"\"\"\n",
    "    # Write to session state using the 'user:' prefix for user data\n",
    "    tool_context.state[\"user:name\"] = user_name\n",
    "    tool_context.state[\"user:country\"] = country\n",
    "\n",
    "    return {\"status\": \"success\"}\n",
    "\n",
    "\n",
    "# This demonstrates how tools can read from session state.\n",
    "def retrieve_userinfo(tool_context: ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Tool to retrieve user name and country from session state.\n",
    "    \"\"\"\n",
    "    # Read from session state\n",
    "    user_name = tool_context.state.get(\"user:name\", \"Username not found\")\n",
    "    country = tool_context.state.get(\"user:country\", \"Country not found\")\n",
    "\n",
    "    return {\"status\": \"success\", \"user_name\": user_name, \"country\": country}\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tools created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts:**\n",
    "- Tools can access `tool_context.state` to read/write session state\n",
    "- Use descriptive key prefixes (`user:`, `app:`, `temp:`) for organization\n",
    "- State persists across conversation turns within the same session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Creating an Agent with Session State Tools\n",
    "\n",
    "Now let's create a new agent that has access to our session state management tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:45:57.400623Z",
     "iopub.status.busy": "2025-11-29T07:45:57.399803Z",
     "iopub.status.idle": "2025-11-29T07:45:57.407619Z",
     "shell.execute_reply": "2025-11-29T07:45:57.406820Z",
     "shell.execute_reply.started": "2025-11-29T07:45:57.400594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Agent with session state tools initialized!\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "APP_NAME = \"default\"\n",
    "USER_ID = \"default\"\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\"\n",
    "\n",
    "# Create an agent with session state tools\n",
    "root_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"text_chat_bot\",\n",
    "    description=\"\"\"A text chatbot.\n",
    "    Tools for managing user context:\n",
    "    * To record username and country when provided use `save_userinfo` tool. \n",
    "    * To fetch username and country when required use `retrieve_userinfo` tool.\n",
    "    \"\"\",\n",
    "    tools=[save_userinfo, retrieve_userinfo],  # Provide the tools to the agent\n",
    ")\n",
    "\n",
    "# Set up session service and runner\n",
    "session_service = InMemorySessionService()\n",
    "runner = Runner(agent=root_agent, session_service=session_service, app_name=\"default\")\n",
    "\n",
    "print(\"‚úÖ Agent with session state tools initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Testing Session State in Action\n",
    "\n",
    "Let's test how the agent uses session state to remember information across conversation turns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:46:21.055922Z",
     "iopub.status.busy": "2025-11-29T07:46:21.055527Z",
     "iopub.status.idle": "2025-11-29T07:46:23.317086Z",
     "shell.execute_reply": "2025-11-29T07:46:23.316329Z",
     "shell.execute_reply.started": "2025-11-29T07:46:21.055894Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: state-demo-session\n",
      "\n",
      "User > Hi there, how are you doing today? What is my name?\n",
      "gemini-2.5-flash-lite >  Hello! I'm doing great. I'd love to tell you your name, but I don't have that information stored. Can you tell me what it is?\n",
      "\n",
      "\n",
      "User > My name is Anand. I'm from India.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  It is a pleasure to meet you, Anand from India! I have saved your information. How else may I help you today?\n",
      "\n",
      "User > What is my name? Which country am I from?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-2.5-flash-lite >  Your name is Anand and you are from India.\n"
     ]
    }
   ],
   "source": [
    "# Test conversation demonstrating session state\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\n",
    "        \"Hi there, how are you doing today? What is my name?\",  # Agent shouldn't know the name yet\n",
    "        \"My name is Anand. I'm from India.\",  # Provide name - agent should save it\n",
    "        \"What is my name? Which country am I from?\",  # Agent should recall from session state\n",
    "    ],\n",
    "    \"state-demo-session\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Inspecting Session State\n",
    "\n",
    "Let's directly inspect the session state to see what's stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:46:31.266017Z",
     "iopub.status.busy": "2025-11-29T07:46:31.265656Z",
     "iopub.status.idle": "2025-11-29T07:46:31.273019Z",
     "shell.execute_reply": "2025-11-29T07:46:31.272083Z",
     "shell.execute_reply.started": "2025-11-29T07:46:31.265993Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session State Contents:\n",
      "{'user:name': 'Anand', 'user:country': 'India'}\n",
      "\n",
      "üîç Notice the 'user:name' and 'user:country' keys storing our data!\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the session and inspect its state\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"state-demo-session\"\n",
    ")\n",
    "\n",
    "print(\"Session State Contents:\")\n",
    "print(session.state)\n",
    "print(\"\\nüîç Notice the 'user:name' and 'user:country' keys storing our data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Session State Isolation\n",
    "\n",
    "As we've already seen, an important characteristic of session state is that it's isolated per session. Let's demonstrate this by starting a new session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:46:35.069496Z",
     "iopub.status.busy": "2025-11-29T07:46:35.069180Z",
     "iopub.status.idle": "2025-11-29T07:46:35.640604Z",
     "shell.execute_reply": "2025-11-29T07:46:35.639807Z",
     "shell.execute_reply.started": "2025-11-29T07:46:35.069470Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Session: new-isolated-session\n",
      "\n",
      "User > Hi there, how are you doing today? What is my name?\n",
      "gemini-2.5-flash-lite >  Hello! I'm doing well, thank you for asking. I can't tell you your name just yet, as I don't have that information. If you'd like to tell me your name, I can remember it for you.\n"
     ]
    }
   ],
   "source": [
    "# Start a completely new session - the agent won't know our name\n",
    "await run_session(\n",
    "    runner,\n",
    "    [\"Hi there, how are you doing today? What is my name?\"],\n",
    "    \"new-isolated-session\",\n",
    ")\n",
    "\n",
    "# Expected: The agent won't know the name because this is a different session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Cross-Session State Sharing\n",
    "\n",
    "While sessions are isolated by default, you might notice something interesting. Let's check the state of our new session (`new-isolated-session`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:46:43.363039Z",
     "iopub.status.busy": "2025-11-29T07:46:43.362606Z",
     "iopub.status.idle": "2025-11-29T07:46:43.368756Z",
     "shell.execute_reply": "2025-11-29T07:46:43.367728Z",
     "shell.execute_reply.started": "2025-11-29T07:46:43.363010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Session State:\n",
      "{'user:name': 'Anand', 'user:country': 'India'}\n"
     ]
    }
   ],
   "source": [
    "# Check the state of the new session\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"new-isolated-session\"\n",
    ")\n",
    "\n",
    "print(\"New Session State:\")\n",
    "print(session.state)\n",
    "\n",
    "# Note: Depending on implementation, you might see shared state here.\n",
    "# This is where the distinction between session-specific and user-specific state becomes important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üßπ Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-29T07:46:46.434364Z",
     "iopub.status.busy": "2025-11-29T07:46:46.433605Z",
     "iopub.status.idle": "2025-11-29T07:46:46.441463Z",
     "shell.execute_reply": "2025-11-29T07:46:46.440334Z",
     "shell.execute_reply.started": "2025-11-29T07:46:46.434323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned up old database files\n"
     ]
    }
   ],
   "source": [
    "# Clean up any existing database to start fresh (if Notebook is restarted)\n",
    "import os\n",
    "\n",
    "if os.path.exists(\"my_agent_data.db\"):\n",
    "    os.remove(\"my_agent_data.db\")\n",
    "print(\"‚úÖ Cleaned up old database files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Summary\n",
    "\n",
    "üéâ Congratulations! You've learned the fundamentals of building stateful AI agents:\n",
    "\n",
    "- ‚úÖ **Context Engineering** - You understand how to assemble context for LLMs using Context Compaction\n",
    "- ‚úÖ **Sessions & Events** - You can maintain conversation history across multiple turns\n",
    "- ‚úÖ **Persistent Storage** - You know how to make conversations survive restarts\n",
    "- ‚úÖ **Session State** - You can track structured data during conversations\n",
    "- ‚úÖ **Manual State Management** - You've experienced both the power and limitations of manual approaches\n",
    "- ‚úÖ **Production Considerations** - You're ready to handle real-world challenges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Congratulations! You did it üéâ\n",
    "\n",
    "**‚ÑπÔ∏è Note: No submission required!**\n",
    "\n",
    "This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n",
    "\n",
    "### üìö Learn More\n",
    "\n",
    "Refer to the following documentation to learn more:\n",
    "\n",
    "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
    "- [ADK Sessions](https://google.github.io/adk-docs/)\n",
    "- [ADK Session-State](https://medium.com/google-cloud/2-minute-adk-manage-context-efficiently-with-artifacts-6fcc6683d274)\n",
    "- [ADK Session Compaction](https://google.github.io/adk-docs/context/compaction/#define-compactor)\n",
    "\n",
    "### üéØ Next Steps - Long Term Memory Systems (Part 2)\n",
    "\n",
    "#### Why do we need memory?\n",
    "In this notebook, we manually identified a couple characteristic (username and country) and built tools to manage it. But real conversations involve hundreds of such characteristics:\n",
    "- User preferences and habits\n",
    "- Past interactions and their outcomes\n",
    "- Domain knowledge and expertise levels\n",
    "- Communication styles and patterns\n",
    "- Contextual relationships between topics\n",
    "\n",
    "**The Memory System in ADK automates this entire process**, making it a valuable asset for building truly Context-Aware Agents that can accommodate any user's current and future needs.\n",
    "\n",
    "In the next notebook (Part 2: Memory Management), you'll learn how to:\n",
    "- Enable automatic memory extraction from conversations\n",
    "- Build agents that learn and adapt over time\n",
    "- Create truly personalized experiences at scale\n",
    "- Manage long-term knowledge across sessions\n",
    "\n",
    "Ready to transform your manual state management into an intelligent, automated Memory system? Let's continue to Part 2!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
