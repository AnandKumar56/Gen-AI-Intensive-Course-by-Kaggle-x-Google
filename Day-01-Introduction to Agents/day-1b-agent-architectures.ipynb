{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"# Installing the Dependencies\n!pip install google-adk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:50:02.886488Z","iopub.execute_input":"2025-11-11T19:50:02.886692Z","iopub.status.idle":"2025-11-11T19:50:10.634473Z","shell.execute_reply.started":"2025-11-11T19:50:02.886672Z","shell.execute_reply":"2025-11-11T19:50:10.633251Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-adk in /usr/local/lib/python3.11/dist-packages (1.18.0)\nRequirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.3)\nRequirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.11.0)\nRequirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.6.5)\nRequirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from google-adk) (8.3.0)\nRequirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.116.1)\nRequirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.177.0)\nRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.125.0)\nRequirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.13.12)\nRequirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.25.0)\nRequirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.56.0)\nRequirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-storage<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.5.0)\nRequirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.48.0)\nRequirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21)\nRequirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.20.0)\nRequirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.12.4)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.9.0.post0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.2.1)\nRequirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.32.5)\nRequirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.17.1)\nRequirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.0.41)\nRequirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.47.2)\nRequirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (9.1.2)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.15.0)\nRequirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from google-adk) (5.3.1)\nRequirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.35.0)\nRequirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.0)\nRequirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (46.0.3)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (6.33.0)\nRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\nRequirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.35.1)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.14.2)\nRequirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\nRequirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\nRequirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\nRequirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\nRequirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\nRequirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (2.4.3)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.2)\nRequirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-secret-manager<3.0.0,>=2.22.0->google-adk) (1.74.0)\nRequirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\nRequirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<4.0.0,>=3.0.0->google-adk) (2.7.2)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\nRequirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\nRequirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.0)\nRequirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.11.0)\nRequirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\nRequirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\nRequirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.3)\nRequirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\nRequirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\nRequirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.26.0)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.4)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\nCollecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk)\n  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.4.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m319.9/319.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf, cachetools\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 6.2.1\n    Uninstalling cachetools-6.2.1:\n      Successfully uninstalled cachetools-6.2.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.5 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cachetools-5.5.2 protobuf-5.29.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:50:18.395034Z","iopub.execute_input":"2025-11-11T19:50:18.395696Z","iopub.status.idle":"2025-11-11T19:50:18.564664Z","shell.execute_reply.started":"2025-11-11T19:50:18.395655Z","shell.execute_reply":"2025-11-11T19:50:18.563663Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:50:22.465587Z","iopub.execute_input":"2025-11-11T19:50:22.466405Z","iopub.status.idle":"2025-11-11T19:51:02.302379Z","shell.execute_reply.started":"2025-11-11T19:50:22.466377Z","shell.execute_reply":"2025-11-11T19:51:02.301530Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:51:21.798688Z","iopub.execute_input":"2025-11-11T19:51:21.798969Z","iopub.status.idle":"2025-11-11T19:51:21.803654Z","shell.execute_reply.started":"2025-11-11T19:51:21.798949Z","shell.execute_reply":"2025-11-11T19:51:21.802703Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:51:36.935505Z","iopub.execute_input":"2025-11-11T19:51:36.935768Z","iopub.status.idle":"2025-11-11T19:51:36.941820Z","shell.execute_reply.started":"2025-11-11T19:51:36.935750Z","shell.execute_reply":"2025-11-11T19:51:36.940849Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:51:43.221261Z","iopub.execute_input":"2025-11-11T19:51:43.222057Z","iopub.status.idle":"2025-11-11T19:51:43.227118Z","shell.execute_reply.started":"2025-11-11T19:51:43.222027Z","shell.execute_reply":"2025-11-11T19:51:43.226270Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:51:47.461788Z","iopub.execute_input":"2025-11-11T19:51:47.462075Z","iopub.status.idle":"2025-11-11T19:51:47.467989Z","shell.execute_reply.started":"2025-11-11T19:51:47.462054Z","shell.execute_reply":"2025-11-11T19:51:47.467239Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in AI and how could they impact human life?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:53:37.446863Z","iopub.execute_input":"2025-11-11T19:53:37.447233Z","iopub.status.idle":"2025-11-11T19:53:45.029712Z","shell.execute_reply.started":"2025-11-11T19:53:37.447209Z","shell.execute_reply":"2025-11-11T19:53:45.028807Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in AI and how could they impact human life?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in AI are significantly impacting human life by increasing efficiency and personalizing experiences across many sectors. AI is integrated into daily activities, from smart home devices to navigation apps. Key areas of advancement include:\n\n*   **Healthcare:** Improved diagnostics, early disease detection, and personalized treatment plans.\n*   **Transportation:** Development of self-driving vehicles and optimized traffic management systems.\n*   **Finance:** Automated investment management, market trend analysis, and fraud detection.\n*   **Communication:** Email categorization, AI-powered chatbots, and real-time language translation.\n*   **Business & Economy:** Driving innovation, increasing efficiency, and projected to contribute trillions to the global economy.\n*   **Education:** Personalized learning experiences tailored to individual student needs.\n\nWhile AI presents numerous benefits, ethical considerations such as bias, privacy, transparency, and accountability are crucial for its responsible integration. The continuous evolution of AI, especially generative AI, is expanding its role in everyday life and various industries.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:54:38.308118Z","iopub.execute_input":"2025-11-11T19:54:38.308472Z","iopub.status.idle":"2025-11-11T19:54:38.313959Z","shell.execute_reply.started":"2025-11-11T19:54:38.308449Z","shell.execute_reply":"2025-11-11T19:54:38.313094Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:54:42.053777Z","iopub.execute_input":"2025-11-11T19:54:42.054147Z","iopub.status.idle":"2025-11-11T19:54:42.059519Z","shell.execute_reply.started":"2025-11-11T19:54:42.054079Z","shell.execute_reply":"2025-11-11T19:54:42.058690Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:55:01.792992Z","iopub.execute_input":"2025-11-11T19:55:01.793336Z","iopub.status.idle":"2025-11-11T19:55:01.799067Z","shell.execute_reply.started":"2025-11-11T19:55:01.793312Z","shell.execute_reply":"2025-11-11T19:55:01.797957Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:55:09.472066Z","iopub.execute_input":"2025-11-11T19:55:09.472855Z","iopub.status.idle":"2025-11-11T19:55:09.477465Z","shell.execute_reply.started":"2025-11-11T19:55:09.472827Z","shell.execute_reply":"2025-11-11T19:55:09.476677Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about Google's new experimental AI tools.\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:56:49.178014Z","iopub.execute_input":"2025-11-11T19:56:49.178884Z","iopub.status.idle":"2025-11-11T19:56:55.530874Z","shell.execute_reply.started":"2025-11-11T19:56:49.178855Z","shell.execute_reply":"2025-11-11T19:56:55.530206Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about Google's new experimental AI tools.\nOutlineAgent > Here's a blog outline about Google's new experimental AI tools:\n\n## Headline: Beyond the Search Bar: Unpacking Google's Daring Dive into Experimental AI\n\n### Introduction Hook:\nRemember when Google was just about finding information? Well, prepare for a seismic shift. Google is no longer content with merely organizing the world's data; they're actively shaping its creation and interaction with a suite of cutting-edge, experimental AI tools. This isn't just an evolution; it's a revolution, and we're getting a sneak peek behind the curtain.\n\n### Main Sections:\n\n**1. The Generative Frontier: AI as Your Creative Co-Pilot**\n\n*   **Text Generation Beyond Search:** Explore how tools like Bard and others are moving beyond simple answers to generating narratives, poems, code, and even entire scripts, acting as a brainstorming partner or a content creator.\n*   **Visualizing the Impossible:** Discuss AI's ability to conjure images, art, and even videos from textual prompts, democratizing creative expression and blurring the lines between imagination and reality.\n*   **The Code Whisperer:** Delve into how AI is assisting developers by generating code snippets, debugging, and even explaining complex programming concepts, accelerating the software development lifecycle.\n\n**2. Bridging the Gap: AI for Enhanced Understanding and Interaction**\n\n*   **Smarter Search, Deeper Insights:** Examine how experimental AI is enhancing Google Search with more nuanced understanding of queries, summarizing complex topics, and surfacing connections users might have missed.\n*   **Conversational Computing Reimagined:** Look at the advancements in natural language processing that are making interactions with AI more fluid, intuitive, and human-like, moving towards true digital assistants.\n*   **Accessibility Amplified:** Consider how AI tools are being developed to break down language barriers, assist with communication for individuals with disabilities, and make information more universally accessible.\n\n**3. The Ethical Tightrope: Navigating the Uncharted AI Territory**\n\n*   **Bias and Fairness in AI Development:** Address the crucial challenges of ensuring AI models are trained on diverse data and don't perpetuate existing societal biases.\n*   **The Future of Information Integrity:** Discuss the implications of AI-generated content on truth, misinformation, and the need for robust detection and verification mechanisms.\n*   **Responsible Innovation and User Control:** Explore Google's stated commitment to ethical AI development, transparency, and giving users control over their data and AI interactions.\n\n### Concluding Thought:\nGoogle's foray into experimental AI is more than just a technological sprint; it's an invitation to reimagine our digital lives. As these tools mature, they hold the potential to unlock unprecedented levels of creativity, understanding, and efficiency. The journey is just beginning, and by staying informed and engaged, we can help shape a future where AI empowers us all.\nWriterAgent > ## Beyond the Search Bar: Unpacking Google's Daring Dive into Experimental AI\n\nRemember when Google was just about finding information? Prepare for a seismic shift. Google is no longer content with merely organizing the world's data; they're actively shaping its creation and interaction with a suite of cutting-edge, experimental AI tools. This isn't just an evolution; it's a revolution, and we're getting a sneak peek behind the curtain.\n\nThe generative frontier is expanding rapidly. Tools like Bard are moving beyond simple answers to become creative co-pilots, generating narratives, poems, and even code. Imagine an AI that can conjure art and videos from your wildest textual prompts, democratizing creative expression. For developers, AI is becoming a \"code whisperer,\" assisting with snippets, debugging, and explaining complex concepts, accelerating innovation.\n\nBeyond creation, Google's experimental AI is enhancing understanding. Search is becoming more nuanced, capable of summarizing complex topics and uncovering hidden connections. Conversational AI is evolving, making interactions more fluid and human-like, paving the way for truly intelligent digital assistants. Furthermore, these tools hold immense promise for accessibility, breaking down language barriers and aiding communication for those with disabilities.\n\nHowever, this leap forward isn't without its challenges. Navigating the ethical tightrope is crucial. Google is grappling with bias in AI development, the integrity of AI-generated information, and the critical need for responsible innovation and user control.\n\nGoogle's foray into experimental AI is an invitation to reimagine our digital lives. As these tools mature, they promise unprecedented levels of creativity, understanding, and efficiency. The journey is just beginning, and by staying informed, we can help shape a future where AI empowers us all.\nEditorAgent > ## Beyond the Search Bar: Unpacking Google's Daring Dive into Experimental AI\n\nRemember when Google was synonymous with a simple search bar, a gateway to the world's information? Prepare for a seismic shift. Google is no longer content with merely organizing data; they are actively shaping its creation and interaction through a suite of cutting-edge, experimental AI tools. This isn't just an evolution; it's a revolution, and we're getting an exciting glimpse behind the curtain.\n\nThe generative frontier is expanding at an unprecedented pace. Tools like Bard are evolving from simple answer-providers into creative co-pilots, capable of generating narratives, poems, and even code. Imagine an AI that can conjure art and videos from your wildest textual prompts, democratizing creative expression and blurring the lines between imagination and reality. For developers, AI is becoming a \"code whisperer,\" assisting with code snippets, debugging, and explaining complex programming concepts, thereby accelerating the pace of innovation.\n\nBeyond creation, Google's experimental AI is fundamentally enhancing our understanding. Search is becoming more nuanced, capable of summarizing intricate topics and uncovering hidden connections that might otherwise remain elusive. Conversational AI is evolving rapidly, making interactions more fluid and human-like, paving the way for truly intelligent digital assistants. Furthermore, these advancements hold immense promise for accessibility, offering to break down language barriers and aid communication for individuals with disabilities, making information more universally accessible.\n\nHowever, this ambitious leap forward is not without its challenges. Navigating the ethical tightrope is crucial. Google is actively grappling with the inherent biases in AI development, ensuring the integrity of AI-generated information, and recognizing the critical need for responsible innovation and robust user control.\n\nGoogle's foray into experimental AI is an invitation to reimagine our digital lives. As these powerful tools mature, they promise unprecedented levels of creativity, understanding, and efficiency. The journey is just beginning, and by staying informed and engaged, we can all help shape a future where AI truly empowers us.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:57:45.772550Z","iopub.execute_input":"2025-11-11T19:57:45.773176Z","iopub.status.idle":"2025-11-11T19:57:45.778477Z","shell.execute_reply.started":"2025-11-11T19:57:45.773131Z","shell.execute_reply":"2025-11-11T19:57:45.777290Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:57:49.647955Z","iopub.execute_input":"2025-11-11T19:57:49.648391Z","iopub.status.idle":"2025-11-11T19:57:49.655405Z","shell.execute_reply.started":"2025-11-11T19:57:49.648358Z","shell.execute_reply":"2025-11-11T19:57:49.654227Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:57:59.034600Z","iopub.execute_input":"2025-11-11T19:57:59.035450Z","iopub.status.idle":"2025-11-11T19:57:59.040530Z","shell.execute_reply.started":"2025-11-11T19:57:59.035420Z","shell.execute_reply":"2025-11-11T19:57:59.039613Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:02.479179Z","iopub.execute_input":"2025-11-11T19:58:02.479925Z","iopub.status.idle":"2025-11-11T19:58:02.485542Z","shell.execute_reply.started":"2025-11-11T19:58:02.479887Z","shell.execute_reply":"2025-11-11T19:58:02.484780Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:06.194241Z","iopub.execute_input":"2025-11-11T19:58:06.194543Z","iopub.status.idle":"2025-11-11T19:58:06.200522Z","shell.execute_reply.started":"2025-11-11T19:58:06.194523Z","shell.execute_reply":"2025-11-11T19:58:06.199518Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:09.697689Z","iopub.execute_input":"2025-11-11T19:58:09.698637Z","iopub.status.idle":"2025-11-11T19:58:15.852195Z","shell.execute_reply.started":"2025-11-11T19:58:09.698604Z","shell.execute_reply":"2025-11-11T19:58:15.851209Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **AI/ML Trends Shaping 2025: Key Developments and Impacts**\n\nArtificial Intelligence (AI) and Machine Learning (ML) continue to be transformative forces across industries. Three key developments dominating the landscape in 2025 are:\n\n1.  **Generative AI and Advanced Content Creation:** This trend focuses on AI's ability to create novel content, including text, images, video, and music. Major companies like **Google** (with models like Imagen and Muse) and **OpenAI** are at the forefront. The impact is a revolution in content creation, personalized marketing, and accelerated artistic expression.\n\n2.  **Explainable and Ethical AI:** As AI becomes more integrated, there's a growing demand for transparency in its decision-making processes. This is crucial for trust and regulatory compliance, especially in sectors like healthcare and finance. Companies are investing in making AI models interpretable. The impact includes increased trust in AI systems, better risk management, and adherence to ethical guidelines.\n\n3.  **AI-Powered Agents and Autonomous Systems:** AI agents are increasingly capable of handling complex tasks independently, impacting logistics, customer support, and predictive maintenance. Companies like **Amazon** are leveraging AI for efficiency in supply chains and customer interactions. The impact is enhanced productivity, reduced operational costs, and the potential for autonomous operations in various sectors.\n\nLeading companies in the AI/ML space include **Google, Microsoft, OpenAI, Meta, NVIDIA, Amazon, Anthropic,** and **Databricks**. These advancements promise significant improvements in efficiency, innovation, and decision-making across technology, health, and finance.\nHealthResearcher > **Health Breakthroughs:**\n\n*   **mRNA Vaccines:** Revolutionizing vaccine development, mRNA technology allows for rapid creation of vaccines for infectious diseases and is being explored for cancer treatments. Full clinical application is ongoing, with wider adoption expected within the next 1-3 years.\n*   **Living Mitral Valve Transplants:** A pioneering procedure using donor living valves for children could eliminate the need for multiple replacements as they grow. This innovation is in early stages, with broader availability anticipated in 5-10 years.\n*   **AI in Diagnostics:** Artificial intelligence is enhancing diagnostic accuracy and speed, particularly in areas like sepsis detection and personalized medicine. Widespread clinical integration is expected within 3-5 years.\n\n**Tech Breakthroughs:**\n\n*   **Generative AI in Research:** Large Language Models (LLMs) are accelerating drug discovery and protein development by analyzing complex biological data. Practical applications are emerging now, with significant impact expected in 1-3 years.\n*   **Quantum Computing:** Advancements in quantum algorithms and hardware promise to solve problems intractable for classical computers, impacting cybersecurity and drug discovery. Commercial viability is estimated within 5-10 years.\n*   **Extended Reality (XR):** Blending AR and VR offers immersive experiences for training, remote collaboration, and healthcare. Market growth suggests widespread adoption within the next 2-5 years.\n\n**Finance Breakthroughs:**\n\n*   **Embedded Finance:** Financial services are increasingly integrated into non-financial platforms, simplifying transactions. This trend is already significant and projected to grow substantially by 2026.\n*   **AI-Powered Personalization:** AI is driving hyper-personalized financial services and risk assessment. This is a rapidly evolving area with immediate and ongoing impact.\n*   **Decentralized Finance (DeFi):** Maturing DeFi protocols are offering enhanced security and scalability, potentially challenging traditional financial systems. Broader adoption is expected within the next 3-7 years.\nFinanceResearcher > Here's a daily executive briefing for November 11, 2025, covering key trends in Tech, Health, and Finance.\n\n**Tech:**\n*   **Generative AI Proliferation:** Generative AI continues its rapid expansion, impacting customer service, content creation, and software development with tools like AI coding platforms gaining millions of users.\n*   **AI Infrastructure Boom:** Major tech companies are investing heavily in AI cloud infrastructure and data centers, with significant deals and new hubs being established globally.\n*   **Market Implications:** Businesses are leveraging AI for faster decision-making and innovation, while top researchers are leaving large tech firms to launch their own AI ventures.\n*   **Future Outlook:** Expect continued AI integration across industries, increased demand for specialized AI hardware, and a potential talent migration towards independent AI startups.\n\n**Health:**\n*   **\"Food is Medicine\" Initiatives:** Healthcare systems are increasingly integrating food-based nutrition programs to manage chronic illnesses and improve health equity, especially with the rise of GLP-1 drugs.\n*   **Data Quality in Healthcare:** Poor data quality remains a significant challenge, hindering data-driven decision-making and AI adoption in health and human services.\n*   **Market Implications:** Payers are exploring cost-effective nutrition interventions, while health organizations grapple with foundational data issues impacting service delivery and analytics.\n*   **Future Outlook:** Greater emphasis on preventative care through nutrition, advancements in personalized medicine, and a focus on improving data integrity for better health outcomes and AI integration.\n\n**Finance:**\n*   **AI-Driven Market Growth:** Financial markets, particularly the S&P 500, are showing strong performance driven by AI-related growth expectations and resilient tech sector earnings.\n*   **Data Architecture for AI:** A significant majority of companies recognize the need to overhaul their data architectures to effectively implement AI initiatives.\n*   **Market Implications:** AI is viewed as a long-term productivity driver, influencing investment strategies and driving demand for robust data management.\n*   **Future Outlook:** Continued integration of AI in financial services, a focus on data governance and architecture for AI scalability, and potential for AI to reshape market forecasts and investment strategies.\nAggregatorAgent > ## Executive Summary: Cross-Sectoral Trends and Key Takeaways\n\n**AI is the dominant, cross-cutting theme**, profoundly impacting Technology, Health, and Finance. Its proliferation is driving innovation, efficiency, and new market opportunities across all sectors. Generative AI is revolutionizing content creation and research, while AI-powered agents are enhancing productivity and autonomous operations. However, the widespread adoption of AI in healthcare is currently hampered by significant data quality challenges, highlighting a crucial area for improvement.\n\nIn **Health**, beyond AI's diagnostic capabilities, advancements like mRNA vaccines and novel transplant procedures signify a push towards faster, more personalized, and potentially curative treatments. Preventative care, exemplified by \"Food is Medicine\" initiatives, is also gaining traction, especially in managing chronic illnesses.\n\n**Finance** is experiencing robust market growth fueled by AI, with embedded finance simplifying transactions and AI-powered personalization driving customer engagement. A critical enabler for both finance and health is the recognized need to overhaul **data architecture** to effectively support AI initiatives.\n\n**Key Takeaways:**\n\n*   **AI's pervasive influence** requires strategic investment in infrastructure and talent.\n*   **Data quality and architecture** are foundational for unlocking AI's full potential across all sectors.\n*   The future points towards **increased personalization, automation, and preventative approaches** in Health and Finance, powered by AI and emerging technologies.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:36.852013Z","iopub.execute_input":"2025-11-11T19:58:36.852789Z","iopub.status.idle":"2025-11-11T19:58:36.858217Z","shell.execute_reply.started":"2025-11-11T19:58:36.852751Z","shell.execute_reply":"2025-11-11T19:58:36.857214Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:45.665578Z","iopub.execute_input":"2025-11-11T19:58:45.666401Z","iopub.status.idle":"2025-11-11T19:58:45.672925Z","shell.execute_reply.started":"2025-11-11T19:58:45.666365Z","shell.execute_reply":"2025-11-11T19:58:45.671935Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:58:51.963410Z","iopub.execute_input":"2025-11-11T19:58:51.963708Z","iopub.status.idle":"2025-11-11T19:58:51.968496Z","shell.execute_reply.started":"2025-11-11T19:58:51.963687Z","shell.execute_reply":"2025-11-11T19:58:51.967565Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:59:03.431766Z","iopub.execute_input":"2025-11-11T19:59:03.432659Z","iopub.status.idle":"2025-11-11T19:59:03.438125Z","shell.execute_reply.started":"2025-11-11T19:59:03.432631Z","shell.execute_reply":"2025-11-11T19:59:03.437247Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T19:59:09.564076Z","iopub.execute_input":"2025-11-11T19:59:09.564413Z","iopub.status.idle":"2025-11-11T19:59:09.570175Z","shell.execute_reply.started":"2025-11-11T19:59:09.564390Z","shell.execute_reply":"2025-11-11T19:59:09.569371Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a guy from a small village who future of India.\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T20:01:06.166416Z","iopub.execute_input":"2025-11-11T20:01:06.166757Z","iopub.status.idle":"2025-11-11T20:01:16.048383Z","shell.execute_reply.started":"2025-11-11T20:01:06.166729Z","shell.execute_reply":"2025-11-11T20:01:16.047533Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a guy from a small village who future of India.\nInitialWriterAgent > Rohan‚Äôs fingers, calloused from tilling his family‚Äôs small plot of land, traced the glowing circuits on the tablet. In his village of Dhampur, electricity was a luxury, internet an impossible dream. Yet, here he was, a self-taught prodigy, learning about solar energy, hydroponics, and coding. He‚Äôd scavenged parts, traded meager produce for old electronics, and poured over downloaded PDFs at the nearest town, a grueling ten-mile bicycle ride. The elders spoke of tradition, of the soil that had sustained generations. Rohan nodded, but his gaze was fixed on a different kind of harvest ‚Äì a future where Dhampur thrived not just on rain and sun, but on innovation, a future he was determined to build.\nCriticAgent > The story presents a compelling setup for a character driven by ambition and innovation against a backdrop of traditional village life.\n\nHere are a few suggestions for improvement:\n\n1.  **Show, Don't Just Tell, Rohan's Prodigy Status:** While the text states Rohan is a \"self-taught prodigy,\" it would be more impactful to demonstrate this through his actions or a brief, specific example of his ingenuity. For instance, could he have already jury-rigged a small solar-powered device for his family or used his learned knowledge to solve a minor village problem? This would solidify his \"prodigy\" status from the outset.\n2.  **Introduce Conflict or Obstacles:** The story effectively sets up Rohan's ambition, but there's an opportunity to deepen the narrative by introducing a specific obstacle or conflict. This could be the direct disapproval of a specific elder, a technical challenge he‚Äôs struggling to overcome, or a practical barrier like a lack of resources that threatens his progress. This would create more tension and make his determination even more significant.\n3.  **Hint at a Specific Future Vision:** The ending mentions a \"future where Dhampur thrived not just on rain and sun, but on innovation.\" To make this more concrete and engaging, consider adding a subtle hint about what this innovation might look like specifically. Is he planning to build a community solar grid? Introduce a water-saving hydroponic system? Develop an app for local farmers? A more specific glimpse, even a brief one, would make his ultimate goal more tangible for the reader.\nRefinerAgent > Rohan‚Äôs fingers, calloused from tilling his family‚Äôs small plot of land, traced the glowing circuits on the tablet. In his village of Dhampur, electricity was a luxury, internet an impossible dream. Yet, here he was, a self-taught prodigy. Just last week, he‚Äôd rigged a small solar panel scavenged from an old inverter to power his mother‚Äôs sewing machine, saving her precious kerosene. He‚Äôd traded meager produce for old electronics, and poured over downloaded PDFs at the nearest town, a grueling ten-mile bicycle ride away. The elders, led by the stern Patel, spoke of tradition, of the soil that had sustained generations. Patel had even scoffed at Rohan‚Äôs solar contraption, muttering about disrupting the natural order. Rohan nodded respectfully, but his gaze was fixed on a different kind of harvest. He envisioned Dhampur not just with a community solar grid, but with a water-saving hydroponic system he‚Äôd only read about, a future where the village thrived not just on rain and sun, but on innovation. A future he was determined to build, Patel‚Äôs disapproval and the scarcity of parts be damned.\nCriticAgent > The story is improved with the addition of a concrete example of Rohan's ingenuity (powering his mother's sewing machine). The introduction of Patel provides a clear antagonist and source of conflict. The future vision is also more specific now.\n\nHowever, the pacing feels a bit rushed in places. While the conflict with Patel is established, it's not fully explored, and Rohan's determination feels stated rather than earned through deeper struggle.\n\nHere are 2-3 specific, actionable suggestions for improvement:\n\n1.  **Deepen the Conflict with Patel:** Instead of just scoffing, have Patel actively try to dissuade Rohan or even sabotage his efforts in a small, believable way. This could involve the elders debating Rohan's ideas, or Patel subtly turning villagers against him by appealing to their fear of change. This would make Rohan's determination to \"build\" his future more impactful and earned.\n2.  **Show, Don't Just Tell, the Scarcity of Parts:** The story mentions \"scarcity of parts\" and \"meager produce\" for trades. To enhance this, include a brief scene or mention of a specific instance where Rohan is particularly challenged by this. Perhaps he desperately needs a specific component and has to make a particularly difficult trade, or he has to improvise with something unexpected. This would make his resourcefulness more vivid.\n3.  **Add a Moment of Doubt or Setback:** Rohan's determination is strong, but a brief moment where he questions his path or faces a significant setback (perhaps related to the scarcity of parts or Patel's opposition) could add emotional depth and make his eventual success feel more triumphant. This doesn't need to be a major event, but a small internal struggle or an external challenge that tests his resolve.\nRefinerAgent > Rohan‚Äôs fingers, calloused from tilling his family‚Äôs small plot of land, traced the glowing circuits on the tablet. In his village of Dhampur, electricity was a luxury, internet an impossible dream. Yet, here he was, a self-taught prodigy. Just last week, he‚Äôd rigged a small solar panel scavenged from an old inverter to power his mother‚Äôs sewing machine, saving her precious kerosene. He‚Äôd traded meager produce for old electronics, and poured over downloaded PDFs at the nearest town, a grueling ten-mile bicycle ride away.\n\nThe elders, led by the stern Patel, spoke of tradition, of the soil that had sustained generations. Patel had even scoffed at Rohan‚Äôs solar contraption, muttering about disrupting the natural order. \"This is not the Dhampur way, Rohan,\" he‚Äôd declared at the last village meeting, his voice resonating with the weight of their ancestors. \"The sun and rain have always been enough. Why invite trouble with your foreign gadgets?\" Some villagers, swayed by Patel's words and their own ingrained caution, began to eye Rohan with suspicion.\n\nRohan nodded respectfully, but his gaze was fixed on a different kind of harvest. He envisioned Dhampur not just with a community solar grid, but with a water-saving hydroponic system he‚Äôd only read about. A future where the village thrived not just on rain and sun, but on innovation. But doubt gnawed at him. The solar panel for his mother‚Äôs machine had been a stroke of luck, a fortuitous find. Now, he desperately needed a specific type of diode for a more ambitious project ‚Äì a small weather station to predict rainfall for the entire village. He‚Äôd scoured every stall in the nearest town, offering his family's best mangoes for the tiny component, but it was nowhere to be found. He returned disheartened, the weight of Patel's disapproval and the crushing reality of scarcity pressing down on him. Was he chasing a mirage? Could he truly bring this future to life with nothing but salvaged scraps and downloaded dreams? He slumped onto his cot, the tablet‚Äôs screen casting a lonely glow on his face, momentarily dimmed by a flicker of despair. But then, his eyes fell upon an old, discarded radio, its casing cracked. An idea sparked. Perhaps, just perhaps, he could salvage something from it. He picked it up, a renewed sense of determination hardening his features. Patel‚Äôs disapproval and the scarcity of parts be damned. He would find a way.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}}]}